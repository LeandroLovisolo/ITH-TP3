\documentclass[10pt,a4paper]{article}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{lipsum}

% Formato del header y footer
\usepackage{lastpage}
\usepackage{fancyhdr}
\lhead{\small Introducción a las Tecnologías del Habla, TP 3: Aprendizaje Automático}
\chead{}
\rhead{\small Leandro Lovisolo (LU 645/11)}
\lfoot{\small Departamento de Computación}
\cfoot{\small \thepage/\pageref{LastPage}}
\rfoot{\small Facultad de Cs. Exactas y Naturales - UBA}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\pagestyle{fancyplain}

% Fomato del título
\usepackage{titling}
\title{Trabajo Práctico 3:\\Aprendizaje Automático}
\author{Leandro Lovisolo\\LU 645/11}
\date{Segundo Cuatrimestre de 2012}

% Esconder números de sección, subsección y etc.
\setcounter{secnumdepth}{-1} 

\begin{document}

% Título
\pretitle{
  \vspace{-4em}
  \begin{center}
    \Huge Introducción a las Tecnologías del Habla
    \par
  \end{center}
  \vskip 0.5em
  \begin{center}\LARGE
}
\posttitle{
    \par
  \end{center}
  \vskip 0.5em
  \begin{center}
    \small
    Departamento de Computación,\\
    Facultad de Ciencias Exactas y Naturales,\\
    Universidad de Buenos Aires
    \par
  \end{center}
  \vskip 0.5em
}
\maketitle
\thispagestyle{fancyplain}

\section{Introducción}

El objetivo de este trabajo práctico es construir un sistema de reconocimiento automático del género de una persona a partir de una grabación corta de su habla, aplicando técnicas de aprendizaje automático.

Para la realización del sistema se dispone de un corpus de grabaciones recolectadas por todos los alumnos de esta materia durante el TP 1, de las cuales se extrayeron el género del hablante y un conjunto de atributos acústicos que serán utilizados como referencia para entrenar el sistema y evaluar su eficacia.

El sistema deberá implementarse sobre la suite de aprendizaje automático Weka\footnote{\url{http://www.cs.waikato.ac.nz/ml/weka/}}, en la que se deberá construir un clasificador que tome como entrada los atributos acústicos de una grabación, y decida en base a estos el género de la persona.

En primer lugar, se deberá implementar como \textit{sistema baseline} un clasificador de reglas RIPPER\footnote{Repeated Incremental Pruning to Produce Error Reduction (RIPPER.) Ver \url{http://wiki.pentaho.com/display/DATAMINING/JRip}} utilizando como único atributo la media de la frecuencia fundamental del hablante. En el TP1 habíamos visto que la diferencia de este atributo para cada género era significativa y grande. Ahora veremos cuál es su poder predictivo en esta tarea.

Finalmente, se deberá experimentar con diferentes clasificadores y diferentes conjuntos de atributos, en busca de una configuración que arroje buenos resultados. La tasa de aciertos deberá ser mayor o igual a 94\%.

\section{Materiales y métodos}

Las instancias en la base de datos corresponden a los segmentos del habla sin pausas (inter-pausal units o IPUs) de todas las grabaciones. Cada instancia registra el género del hablante y 1582 atributos acústicos.

Los atributos acústicos en la base de datos fueron extraídos de los archivos de audio con la herramienta openSMILE\footnote{\url{http://opensmile.sourceforge.net/}}, usando la configuración para el INTERSPEECH 2010 Paralinguistic Challenge\footnote{\url{http://emotion-research.net/sigs/speech-sig/paralinguistic-challenge}}, y almacenados en formato ARFF para facilitar su lectura desde Weka. Para más información, ver las páginas 30 y 31 del openSMILE book\footnote{\url{http://sourceforge.net/projects/opensmile/files/openSMILE\_book\_1.0.0.pdf}}.

La base de datos de atributos acústicos, junto con el enunciado completo del TP, pueden descargarse desde la siguiente URL: \url{http://habla.dc.uba.ar/gravano/ith-2012/tp3/}

\section{Sistema baseline}

Se empleó un clasificador \texttt{rules.JRip} con opciones de configuración por defecto y cross-validation de 10 folds.

El atributo utilizado fue \texttt{F0Final\_sma\_amean} (media de la frecuencia fundamental.)

\subsection{Resultados}

Se obtuvo un porcentaje de instancias correctamente clasificadas del \textbf{86.9315\%}, con la siguiente matriz de confusión:

\begin{verbatim}
=== Confusion Matrix ===

   a   b   <-- classified as
 660  94 |   a = f
 110 697 |   b = m
\end{verbatim}

\section{Mejor sistema desarrollado}

La mejor configuración hallada fue un clasificador \texttt{trees.J48} con los siguientes atributos:

\begin{description}
\item[mfcc\_sma{[}10{]}\_quartile1]
\item[mfcc\_sma{[}12{]}\_quartile1]
\item[logMelFreqBand\_sma{[}0{]}\_quartile3]
\item[lspFreq\_sma{[}4{]}\_linregerrA]
\item[F0finEnv\_sma\_amean]
\item[shimmerLocal\_sma\_linregc1]
\end{description}

Los atributos fueron seleccionados usando el método de búsqueda \texttt{GreedyStepwise}, con evaluador de atributos \texttt{ClassifierSubsetEval} y clasificador \texttt{rules.JRip}.

\subsection{Resultados}

Se clasificaron correctamente el \textbf{95.0673\%} de las instancias, y se obtuvo la siguiente matriz de confusión:

\begin{verbatim}
=== Confusion Matrix ===

   a   b   <-- classified as
 710  44 |   a = f
  33 774 |   b = m
\end{verbatim}

\section{Otros experimentos conducidos}

\lipsum[1-3]

\end{document}